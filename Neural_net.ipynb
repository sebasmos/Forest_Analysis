{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda91809b139dd24b97ab06595f752137a3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree   import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# compare standalone models for binary classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, LSTM, Dense, Dropout, TimeDistributed, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "# Cross-validation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data\"\n",
    "X = pd.read_csv(f'{data_path}/x_train.csv')\n",
    "y = pd.read_csv(f'{data_path}/y_train.csv')\n",
    "x_testing = pd.read_csv(f'{data_path}/x_test.csv')\n",
    "y_testing = pd.read_csv(f'{data_path}/y_test_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X.columns[1:]]\n",
    "X.columns = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area_1', 'Wilderness_Area_2', 'Wilderness_Area_3', 'Wilderness_Area_4', \n",
    "'Soil_Type_1', 'Soil_Type_2','Soil_Type_3','Soil_Type_4','Soil_Type_5','Soil_Type_6','Soil_Type_7','Soil_Type_8','Soil_Type_9','Soil_Type_10',\n",
    "'Soil_Type_11','Soil_Type_12','Soil_Type_13','Soil_Type_14','Soil_Type_15','Soil_Type_16','Soil_Type_17','Soil_Type_18','Soil_Type_19','Soil_Type_20',\n",
    "'Soil_Type_21','Soil_Type_22','Soil_Type_23','Soil_Type_24','Soil_Type_25','Soil_Type_26','Soil_Type_27','Soil_Type_28','Soil_Type_29','Soil_Type_30',\n",
    "'Soil_Type_31','Soil_Type_32','Soil_Type_33','Soil_Type_34','Soil_Type_35','Soil_Type_36','Soil_Type_37','Soil_Type_38','Soil_Type_39','Soil_Type_40']\n",
    "\n",
    "y = y[y.columns[1:]]\n",
    "y.columns=['Cover_Type']\n",
    "\n",
    "# for testing the models\n",
    "x_testing = x_testing[x_testing.columns[1:]]\n",
    "x_testing.columns = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area_1', 'Wilderness_Area_2', 'Wilderness_Area_3', 'Wilderness_Area_4', \n",
    "'Soil_Type_1', 'Soil_Type_2','Soil_Type_3','Soil_Type_4','Soil_Type_5','Soil_Type_6','Soil_Type_7','Soil_Type_8','Soil_Type_9','Soil_Type_10',\n",
    "'Soil_Type_11','Soil_Type_12','Soil_Type_13','Soil_Type_14','Soil_Type_15','Soil_Type_16','Soil_Type_17','Soil_Type_18','Soil_Type_19','Soil_Type_20',\n",
    "'Soil_Type_21','Soil_Type_22','Soil_Type_23','Soil_Type_24','Soil_Type_25','Soil_Type_26','Soil_Type_27','Soil_Type_28','Soil_Type_29','Soil_Type_30',\n",
    "'Soil_Type_31','Soil_Type_32','Soil_Type_33','Soil_Type_34','Soil_Type_35','Soil_Type_36','Soil_Type_37','Soil_Type_38','Soil_Type_39','Soil_Type_40']\n",
    "y_testing = y_testing[y_testing.columns[1:]]\n",
    "y_testing.columns=['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(406708, 54)\n(406708, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.drop(columns=[\"id\"],inplace=True)\n",
    "#y = y.drop(columns=[\"id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 10, stratify=y['Cover_Type'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train:  (284695, 54)\ny_train:  (284695, 1)\nx_test:  (122013, 54)\ny_test:  (122013, 1)\nx_testing:  (174304, 54)\n"
     ]
    }
   ],
   "source": [
    "# For creating the models\n",
    "print(\"x_train: \",x_train.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"x_test: \",x_test.shape)\n",
    "print(\"y_test: \",y_test.shape)\n",
    "print(\"x_testing: \",x_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = copy.deepcopy(x_train)\n",
    "Y_train = copy.deepcopy(y_train)\n",
    "X_test = copy.deepcopy(x_test)\n",
    "Y_test = copy.deepcopy(y_test)\n",
    "X_testing = copy.deepcopy(x_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train:  (284695, 54)\ny_train:  (284695, 1)\nx_test:  (122013, 54)\ny_test:  (122013, 1)\nx_testing:  (174304, 54)\n"
     ]
    }
   ],
   "source": [
    "# After performing copy with dtype = int64\n",
    "print(\"x_train: \",X_train.shape)\n",
    "print(\"y_train: \",Y_train.shape)\n",
    "print(\"x_test: \",X_test.shape)\n",
    "print(\"y_test: \",Y_test.shape)\n",
    "print(\"x_testing: \",X_testing.shape)"
   ]
  },
  {
   "source": [
    "#### Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "        #createmodel\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 54, activation=\"relu\"))\n",
    "    model.add(Dense(8, activation = 'relu'))\n",
    "    model.add(Dense(7, activation = 'sigmoid'))\n",
    "    # Compile the model\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X_test, clf_object):\n",
    "    y_pred = clf_object.predict(X_test)\n",
    "    print(\"Predicted values: \")\n",
    "    print(y_pred)\n",
    "    return y_pred\n",
    "def calculate_Acc(y_test, y_pred):\n",
    "    print(\"Confusion matrix: \\n\")\n",
    "    confusion_matrix(y_test, y_pred)\n",
    "    print(\"Accuracy: \", accuracy_score(y_test,y_pred)*100)\n",
    "    print(\"Report \", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(284695, 54)\n(284695,)\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 12)                660       \n_________________________________________________________________\ndense_4 (Dense)              (None, 8)                 104       \n_________________________________________________________________\ndense_5 (Dense)              (None, 7)                 63        \n=================================================================\nTotal params: 827\nTrainable params: 827\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "X_train = tf.keras.utils.normalize(X_train)\n",
    "#Y_train = tf.keras.utils.normalize(Y_train).T\n",
    "print(X_train.shape)\n",
    "print(Y_train.values.ravel().shape)\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(284695, 7)\n[[0 1 0 ... 0 0 0]\n [0 1 0 ... 0 0 0]\n [0 1 0 ... 0 0 0]\n ...\n [0 1 0 ... 0 0 0]\n [0 1 0 ... 0 0 0]\n [0 0 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "Y_train = LabelBinarizer().fit_transform(Y_train)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train)\n",
    "#\n",
    "# X_train = np.asarray(X_train).astype(np.float32)\n",
    "Y_train = np.asarray(Y_train).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "28470/28470 - 25s - loss: 0.2438 - accuracy: 0.5860\n",
      "Epoch 2/3\n",
      "28470/28470 - 33s - loss: 0.2058 - accuracy: 0.6732\n",
      "Epoch 3/3\n",
      "28470/28470 - 30s - loss: 0.1981 - accuracy: 0.6837\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b5817a108>"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, epochs=3, batch_size=10,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(122013, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(datum):\n",
    "    return np.argmax(datum)\n",
    "y_pred_dec = []\n",
    "for i in range(y_pred.shape[0]):\n",
    "    label = y_pred[i]\n",
    "    decoded_labels = decode(label)\n",
    "    y_pred_dec.append(decoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5085113881307729\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, y_pred_dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}